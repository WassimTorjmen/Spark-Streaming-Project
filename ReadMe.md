# Spark Streaming Project

## ğŸ“‹ Ã€ propos du projet

**Spark Streaming Project** est une application de traitement de donnÃ©es en temps rÃ©el utilisant Apache Spark.  Ce projet combine la puissance de **Scala** (54.6%) pour le traitement de donnÃ©es haute performance, **Python** (29.3%) pour l'orchestration et l'analyse, et **Docker** (16.1%) pour la containerisation et le dÃ©ploiement.

## ğŸš€ CaractÃ©ristiques principales

### âš¡ Traitement de donnÃ©es en temps rÃ©el avec Apache Spark Streaming

Spark Streaming permet de traiter des flux de donnÃ©es continus avec trÃ¨s faible latence :

- **Micro-batching** : Divise le flux de donnÃ©es en petits lots pour un traitement efficace
- **Basse latence** : Latence de quelques secondes pour les rÃ©sultats
- **Haute throughput** : Traite des millions d'Ã©vÃ©nements par seconde
- **Stateful processing** : Maintient l'Ã©tat entre les micro-batches pour les agrÃ©gations complexes
- **Support multi-sources** : 
  - Kafka, Kinesis, Flume (sources natives)
  - TCP sockets
  - Sources personnalisÃ©es via l'API DStream
- **Garanties de dÃ©livrance** :
  - At-least-once semantics
  - Exactly-once pour certaines opÃ©rations
  - RÃ©cupÃ©ration automatique en cas de dÃ©faillance

### Cas d'usage supportÃ©s

- **AgrÃ©gation en temps rÃ©el** : Calcul de moyennes, sommes, comptages continus
- **DÃ©tection d'anomalies** : Identification de patterns anormaux dans les flux
- **Join de flux** : CorrÃ©lation de donnÃ©es provenant de multiples sources
- **FenÃªtrage temporel** : Sliding windows, tumbling windows
- **Stateful transformations** : MapWithState, UpdateStateByKey pour les opÃ©rations complexes

```scala
// Exemple : AgrÃ©gation sur fenÃªtre glissante
val windowedWordCounts = words
  .map(word => (word, 1))
  .reduceByKeyAndWindow(
    (a: Int, b: Int) => a + b,
    Seconds(60),      // FenÃªtre de 60 secondes
    Seconds(10)       // Slide toutes les 10 secondes
  )
```

---

### ğŸ Scripts Python pour l'orchestration et l'analyse

Une couche Python complÃ¨te pour complÃ©ter Scala :

#### **Orchestration des jobs Spark**
- Gestion des workflows Spark depuis Python
- Soumission dynamique des jobs avec pyspark
- Configuration flexible des paramÃ¨tres
- Gestion des dÃ©pendances et des Ã©tapes

#### **Traitement et nettoyage des donnÃ©es**
- **Pandas** : Manipulation et transformation des donnÃ©es
- **NumPy** : OpÃ©rations numÃ©riques avancÃ©es
- **PySpark DataFrames** : Traitement parallÃ¨le de grandes volumes
- Nettoyage, validation et normalisation des donnÃ©es

#### **Analyse statistique**
- **SciPy** : Statistiques avancÃ©es
- **Scikit-learn** : Machine Learning (clustering, classification, rÃ©gression)
- Analyse exploratoire des donnÃ©es (EDA)
- Rapports statistiques automatisÃ©s

#### **Visualisation et monitoring**
- Dashboards interactifs avec **Streamlit**
- Graphiques en temps rÃ©el avec **Plotly/Matplotlib**
- MÃ©triques de performance et logs
- Alertes et notifications

```python
# Exemple : Pipeline d'analyse Python
import pyspark.sql.functions as F
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("AnalysisPipeline").getOrCreate()

# Charger et traiter les donnÃ©es
df = spark.read.parquet("s3://bucket/data")
result = df.filter(F.col("value") > 100) \
    .groupBy("category") \
    .agg(F.avg("amount").alias("avg_amount"))

# Visualiser avec Streamlit
import streamlit as st
st.dataframe(result. toPandas())
```

#### **IntÃ©gration avec des services externes**
- APIs REST pour rÃ©cupÃ©rer/envoyer des donnÃ©es
- Connexion Ã  des bases de donnÃ©es (PostgreSQL, MongoDB, etc.)
- Interaction avec le cloud (AWS S3, Azure Blob, GCP)
- Webhooks et notifications

---

### ğŸ³ Infrastructure Docker pour dÃ©ploiement facile

Une architecture containerisÃ©e complÃ¨te pour simplifier le dÃ©ploiement :

#### **Avantages du dÃ©ploiement Docker**
- âœ… **ReproductibilitÃ©** : MÃªme environnement sur tous les serveurs
- âœ… **Isolation** : Services indÃ©pendants sans conflits de dÃ©pendances
- âœ… **ScalabilitÃ©** : Lancer plusieurs instances facilement
- âœ… **PortabilitÃ©** : Fonctionne sur Windows, Mac, Linux, Cloud
- âœ… **Versioning** : Tracer les versions d'infrastructure

#### **Architecture multi-conteneurs**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Docker Compose Orchestration                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Spark Master     â”‚  â”‚ Spark Worker (x2+)   â”‚        â”‚
â”‚  â”‚ - Port 8080      â”‚  â”‚ - Dynamic ports      â”‚        â”‚
â”‚  â”‚ - REST API       â”‚  â”‚ - Auto-scaling       â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚           â”‚                     â”‚                      â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                     â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Kafka/Data   â”‚â—„â”€â”€â”´â”€â”€â–ºâ”‚ Streamlit Dashboard  â”‚       â”‚
â”‚  â”‚ Source       â”‚       â”‚ - Port 8501          â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚           â”‚                                            â”‚
â”‚           â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ PostgreSQL/MongoDB           â”‚                      â”‚
â”‚  â”‚ - Persistence                â”‚                      â”‚
â”‚  â”‚ - Port 5432/27017           â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **Configurations Docker disponibles**

**Services inclus :**
- **Spark Master** : Coordonne les jobs et les ressources
- **Spark Workers** : ExÃ©cutent les tÃ¢ches en parallÃ¨le
- **Kafka** (optionnel) : Source de donnÃ©es en temps rÃ©el
- **PostgreSQL/MongoDB** : Stockage persistant
- **Streamlit** : Interface web interactive
- **JupyterLab** (optionnel) : DÃ©veloppement et prototypage

**Avantages de cette approche :**
- Tous les services dÃ©marrent automatiquement
- Networking automatique entre conteneurs
- Partage de volumes pour persistence
- Logs centralisÃ©s
- Facile de scale les workers

```yaml
# Exemple docker-compose.yml simplifiÃ©
version: '3.8'
services:
  spark-master:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=master
    ports:
      - "8080:8080"
  
  spark-worker:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master
    deploy:
      replicas: 3  # Lancer 3 workers
```

---

### ğŸ“Š Architecture modulaire et scalable

Une structure de code bien organisÃ©e pour la maintenabilitÃ© :

#### **ModularitÃ©**
- **SÃ©paration des responsabilitÃ©s** : Chaque module a une fonction clairement dÃ©finie
- **RÃ©utilisabilitÃ©** : Code packagÃ© dans des bibliothÃ¨ques (`libs/`)
- **TestabilitÃ©** : Code dÃ©couplÃ© facile Ã  tester unitairement
- **ExtensibilitÃ©** : Ajouter facilement de nouvelles fonctionnalitÃ©s

#### **ScalabilitÃ© horizontale**
- Ajouter des Spark Workers sans modification du code
- Distribution automatique des charges
- ParallÃ©lisation des transformations
- RDD/DataFrame partitionnÃ©s efficacement

#### **ScalabilitÃ© verticale**
- Augmenter les ressources (CPU, RAM) par conteneur
- Configuration flexible des paramÃ¨tres Spark
- Tuning des partitions et du batch interval

---

### ğŸ”„ Support multi-langage (Scala + Python)

Exploite les forces de deux langages :

#### **Pourquoi Scala ?**
- **Performance** : CompilÃ©, typÃ© statiquement (plus rapide que Python)
- **Naturellement parallÃ¨le** : ImmutabilitÃ©, pas de race conditions
- **DSL expressif** : API Spark trÃ¨s naturelle en Scala
- **Type-safe** : Erreurs dÃ©tectÃ©es Ã  la compilation

#### **Pourquoi Python ?**
- **DÃ©veloppement rapide** : Syntaxe simple et productive
- **Ã‰cosystÃ¨me data science** : Pandas, NumPy, SciPy, Scikit-learn
- **Data scientists friendly** : Langage prÃ©fÃ©rÃ© des analystes
- **IntÃ©grations faciles** : APIs, webhooks, services cloud

#### **InteropÃ©rabilitÃ©**
- Scala pour les jobs Spark haute-performance
- Python pour l'orchestration et la visualisation
- Communication via fichiers (Parquet), API REST, ou messages
- Partage de donnÃ©es via DataFrames

```scala
// Job Scala haute-performance
object StreamingJob {
  def main(args: Array[String]) {
    val ssc = new StreamingContext(sc, Seconds(1))
    val dstream = ssc.socketTextStream("localhost", 9999)
    dstream.map(_.split(" "))
      .map(words => (words(0), 1))
      .reduceByKey(_ + _)
      .saveAsTextFiles("hdfs://path/output")
    ssc.start()
  }
}
```

```python
# Orchestration Python
import subprocess
import pandas as pd

# Soumettre le job Scala
subprocess.run([
    "spark-submit",
    "--class", "com.example.StreamingJob",
    "target/spark-project.jar"
])

# Analyser les rÃ©sultats
results = pd.read_parquet("hdfs://path/output")
print(results.describe())
```

---

## ğŸ“¦ Stack technologique

| Technologie | Pourcentage | Utilisation |
|---|---|---|
| **Scala** | 54.6% | Traitement de donnÃ©es et logique mÃ©tier |
| **Python** | 29.3% | Scripts d'orchestration et visualisation |
| **Docker** | 16.1% | Containerisation et dÃ©ploiement |

---

## ğŸ“ Structure du projet

```
Spark-Streaming-Project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ scala/              # Code Scala principal
â”‚   â”‚   â”‚   â””â”€â”€ com/example/
â”‚   â”‚   â”‚       â”œâ”€â”€ streaming/  # Jobs Spark Streaming
â”‚   â”‚   â”‚       â”œâ”€â”€ utils/      # Utilitaires
â”‚   â”‚   â”‚       â””â”€â”€ config/     # Configuration
â”‚   â”‚   â””â”€â”€ resources/          # Fichiers de config (YAML, properties)
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ scala/              # Tests unitaires Scala
â”‚       â””â”€â”€ python/             # Tests Python
â”œâ”€â”€ streamlit/                  # Applications Streamlit
â”‚   â”œâ”€â”€ app.py                  # Dashboards interactifs
â”‚   â””â”€â”€ components/             # Composants rÃ©utilisables
â”œâ”€â”€ Infra/                      # Configuration infrastructure
â”‚   â”œâ”€â”€ terraform/              # Infrastructure as Code
â”‚   â””â”€â”€ ansible/                # Configuration management
â”œâ”€â”€ libs/                       # BibliothÃ¨ques partagÃ©es
â”‚   â”œâ”€â”€ common/                 # Code commun
â”‚   â””â”€â”€ validators/             # Validateurs
â”œâ”€â”€ pom.xml                     # Configuration Maven
â”œâ”€â”€ docker-compose.yml          # Orchestration Docker
â”œâ”€â”€ Dockerfile                  # Image Docker personnalisÃ©e
â””â”€â”€ ReadMe.md                   # Documentation
```

---

## ğŸ› ï¸ Installation et mise en place

### PrÃ©requis

- Docker et Docker Compose (v1.29+)
- Apache Spark 3.x
- Scala 2.12+
- Python 3.8+
- Maven 3.6+
- Git

### DÃ©marrage rapide avec Docker Compose

```bash
# Cloner le repository
git clone https://github.com/WassimTorjmen/Spark-Streaming-Project.git
cd Spark-Streaming-Project

# DÃ©marrer l'environnement complet
docker-compose up -d

# VÃ©rifier le status
docker-compose ps

# Voir les logs
docker-compose logs -f spark-master
```

### Installation locale

```bash
# Installer les dÃ©pendances Maven
mvn clean install

# Compiler le projet
mvn package

# ExÃ©cuter un job Spark
spark-submit --class com.example.streaming.StreamingApp \
  target/spark-streaming-1.0.jar
```

---

## ğŸ“Š Performances et optimisations

- **Partitionnement intelligent** : Optimisation du nombre de partitions
- **Batch interval tuning** : Ã‰quilibre latence vs throughput
- **RDD caching** : Optimisation des opÃ©rations rÃ©pÃ©tÃ©es
- **Compression de donnÃ©es** : RÃ©duction de l'utilisation mÃ©moire
- **ParallÃ©lisme adaptatif** : Auto-tuning des ressources

---

## ğŸ“ Support

Pour toute question, ouvrez une [issue](https://github.com/WassimTorjmen/Spark-Streaming-Project/issues).

---

**DerniÃ¨re mise Ã  jour** : 26 novembre 2025
