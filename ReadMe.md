# ğŸš€ **Spark Streaming Project â€” Pipeline de traitement de donnÃ©es en temps rÃ©el**

## ğŸ“Œ **Description**

Spark Streaming Project est une plateforme de traitement de donnÃ©es en temps rÃ©el qui collecte, transforme et analyse des donnÃ©es alimentaires provenant de l'API OpenFood. Le projet combine **Apache Spark Streaming** pour le traitement haute performance, **Kafka** pour l'ingestion de flux, **PostgreSQL** pour le stockage persistant, et **Streamlit** pour la visualisation interactive.

Le projet combine **streaming de donnÃ©es**, **architecture microservices**, **traitement distribuÃ©** et **dÃ©ploiement via Docker**. 

---

## ğŸ¯ **Objectif du projet**

* Collecter des donnÃ©es en temps rÃ©el depuis l'API OpenFood. 
* Traiter et transformer les flux de donnÃ©es avec Apache Spark Streaming.
* Stocker les donnÃ©es traitÃ©es dans PostgreSQL.
* Visualiser les rÃ©sultats via un dashboard Streamlit interactif.
* Offrir une infrastructure complÃ¨te, scalable et facilement dÃ©ployable.

---

## ğŸ§  **Contexte & ProblÃ©matique**

L'analyse de donnÃ©es alimentaires Ã  grande Ã©chelle nÃ©cessite un pipeline robuste capable de :
- GÃ©rer des volumes importants de donnÃ©es en continu.
- Assurer une faible latence entre l'ingestion et l'analyse.
- Offrir une visualisation en temps rÃ©el des rÃ©sultats. 

Spark Streaming Project rÃ©sout ce problÃ¨me en :

* **IngÃ©rant automatiquement** les donnÃ©es via Kafka.
* **Traitant les flux** avec Spark Streaming.
* **Persistant les rÃ©sultats** dans PostgreSQL. 
* **Exposant un dashboard** interactif pour l'analyse.

---

## ğŸ—ï¸ **Architecture du pipeline**

1. **Producer (Ingestion)**

   * RÃ©cupÃ©ration des donnÃ©es depuis l'API OpenFood. 
   * Publication des messages dans Kafka.
   * Configuration du batch et de l'offset.

2. **Kafka (Message Broker)**

   * Gestion du flux de donnÃ©es en temps rÃ©el. 
   * Coordination via ZooKeeper.
   * Garantie de dÃ©livrance des messages.

3. **Consumer (Traitement Spark)**

   * Lecture des messages Kafka.
   * Transformation et nettoyage des donnÃ©es.
   * AgrÃ©gations et calculs en temps rÃ©el. 
   * Ã‰criture dans PostgreSQL.

4. **PostgreSQL (Stockage)**

   * Persistance des donnÃ©es traitÃ©es.
   * Base de donnÃ©es `openfood`.
   * Scripts d'initialisation automatiques.

5. **Streamlit (Visualisation)**

   * Dashboard interactif. 
   * Graphiques et mÃ©triques en temps rÃ©el.
   * Connexion directe Ã  PostgreSQL.

6. **Docker & Infrastructure**

   * Orchestration multi-conteneurs via Docker Compose.
   * RÃ©seaux isolÃ©s (backend-net, frontend-net). 
   * Volumes persistants pour les donnÃ©es.

---

## ğŸ› ï¸ **Technologies utilisÃ©es**

**Langages :**

* Scala (54. 6%)
* Python (29.3%)
* Docker (16.1%)

**Traitement de donnÃ©es :**

* Apache Spark 3.5.5
* Spark Streaming
* Spark SQL

**Message Broker :**

* Apache Kafka
* Apache ZooKeeper

**Base de donnÃ©es :**

* PostgreSQL 15

**Visualisation :**

* Streamlit
* Plotly / Matplotlib

**Infra & DevOps :**

* Docker & Docker Compose
* Maven
* Git

---

## ğŸ“š **CompÃ©tences mobilisÃ©es**

### **Big Data & Streaming**

* Apache Spark Streaming
* Micro-batching
* FenÃªtrage temporel (sliding/tumbling windows)
* Stateful processing
* Kafka integration

### **Data Engineering**

* Ingestion de donnÃ©es API
* ETL en temps rÃ©el
* Structuration SQL
* Pipelines de traitement distribuÃ©s

### **Backend & DevOps**

* Architecture microservices
* Containerisation Docker
* Orchestration Docker Compose
* Configuration infrastructure

---

## ğŸš€ **FonctionnalitÃ©s principales**

* Collecte automatique de donnÃ©es depuis l'API OpenFood. 
* Traitement en temps rÃ©el avec Spark Streaming.
* Stockage persistant dans PostgreSQL.
* Dashboard Streamlit interactif.
* Infrastructure complÃ¨te containerisÃ©e. 
* ScalabilitÃ© horizontale des workers Spark.

---

## ğŸ“‚ **Structure du projet**

```
Spark-Streaming-Project/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main/
â”‚       â””â”€â”€ scala/
â”‚           â””â”€â”€ com/esgi/
â”‚               â”œâ”€â”€ Producer/          # Producer Kafka
â”‚               â”‚   â””â”€â”€ Dockerfile
â”‚               â””â”€â”€ Consumer/          # Consumer Spark Streaming
â”‚                   â””â”€â”€ Dockerfile
â”œâ”€â”€ streamlit/                         # Application Streamlit
â”‚   â”œâ”€â”€ app.py                         # Dashboard principal
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ Infra/                             # Configuration infrastructure
â”‚   â”œâ”€â”€ kafka/                         # Configuration Kafka
â”‚   â”œâ”€â”€ postgres/                      # Scripts SQL d'initialisation
â”‚   â”‚   â””â”€â”€ init.sql
â”‚   â”œâ”€â”€ zookeeper/                     # Configuration ZooKeeper
â”‚   â””â”€â”€ docker-compose.yml             # Compose infrastructure
â”œâ”€â”€ libs/                              # BibliothÃ¨ques partagÃ©es
â”œâ”€â”€ data/                              # DonnÃ©es locales
â”œâ”€â”€ pom.xml                            # Configuration Maven
â”œâ”€â”€ docker-compose.yml                 # Orchestration principale
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## â–¶ï¸ **Installation & ExÃ©cution**

### 1.  Cloner le projet

```bash
git clone https://github.com/WassimTorjmen/Spark-Streaming-Project. git
cd Spark-Streaming-Project
```

### 2. DÃ©marrer l'environnement complet

```bash
docker-compose up -d
```

### 3. VÃ©rifier le statut des services

```bash
docker-compose ps
```

### 4. Voir les logs

```bash
# Logs du producer
docker-compose logs -f producer

# Logs du consumer
docker-compose logs -f consumer

# Logs Kafka
docker-compose logs -f kafka
```

### 5.  AccÃ©der au dashboard Streamlit

ğŸ‘‰ [http://localhost:8501](http://localhost:8501)

### 6. AccÃ©der Ã  PostgreSQL

```bash
psql -h localhost -p 5433 -U ingest -d openfood
# Mot de passe : ingestpwd
```

---

## ğŸ—ï¸ **Architecture Docker**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Docker Compose Orchestration                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ ZooKeeper        â”‚  â”‚ Kafka                â”‚            â”‚
â”‚  â”‚ - Port 2181      â”‚â—„â”€â”‚ - Port 9092          â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                              â”‚                              â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚           â–¼                  â”‚                  â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Producer         â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚ Consumer (Spark) â”‚ â”‚
â”‚  â”‚ - API OpenFood   â”‚                 â”‚ - Spark Streamingâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                              â”‚              â”‚
â”‚                                              â–¼              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ PostgreSQL                                           â”‚  â”‚
â”‚  â”‚ - Port 5433                                          â”‚  â”‚
â”‚  â”‚ - Base: openfood                                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                              â”‚
â”‚                              â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Streamlit Dashboard                                  â”‚  â”‚
â”‚  â”‚ - Port 8501                                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ **Configuration**

### Variables d'environnement Producer

| Variable | Description | DÃ©faut |
|----------|-------------|--------|
| `KAFKA_BOOTSTRAP_SERVERS` | Adresse Kafka | `kafka:9092` |
| `USE_API` | Utiliser l'API OpenFood | `true` |
| `BATCH_LENGTH` | Taille du batch | `100` |
| `MAX_OFFSET` | Offset maximum | `3808300` |

### Variables d'environnement Consumer

| Variable | Description | DÃ©faut |
|----------|-------------|--------|
| `KAFKA_BOOTSTRAP_SERVERS` | Adresse Kafka | `kafka:9092` |
| `PG_URL` | URL PostgreSQL | `jdbc:postgresql://postgres:5432/openfood` |
| `PG_USER` | Utilisateur PostgreSQL | `ingest` |
| `PG_PWD` | Mot de passe PostgreSQL | `ingestpwd` |
| `CHECKPOINT_PATH` | Chemin checkpoint Spark | `/checkpoint/generic` |

---

## ğŸ“Š **Exemple de flux de donnÃ©es**

### Input (donnÃ©es API OpenFood)

```json
{
  "product_name": "Nutella",
  "brands": "Ferrero",
  "categories": "PÃ¢tes Ã  tartiner",
  "nutriscore_grade": "e",
  "energy_100g": 2252
}
```

### Traitement Spark

```scala
// Lecture depuis Kafka
val stream = spark.readStream
  .format("kafka")
  .option("subscribe", "openfood-topic")
  .load()

// Transformation et agrÃ©gation
val processed = stream
  .select(from_json(col("value"), schema).as("data"))
  .groupBy("data.nutriscore_grade")
  . count()
```

### RÃ©sultat PostgreSQL

| nutriscore_grade | count |
|------------------|-------|
| a | 15234 |
| b | 28451 |
| c | 34123 |
| d | 21098 |
| e | 12456 |

---

## ğŸ§ª **Tests**

### Compilation Maven

```bash
mvn clean install
mvn package
```

### Test de connectivitÃ© Kafka

```bash
docker exec -it kafka kafka-topics. sh --list --bootstrap-server localhost:9092
```

### Test PostgreSQL

```bash
docker exec -it postgres psql -U ingest -d openfood -c "SELECT COUNT(*) FROM products;"
```

---

## ğŸ“ˆ **Performances et optimisations**

* **Partitionnement Kafka** : Distribution optimale des messages. 
* **Checkpointing Spark** : RÃ©cupÃ©ration en cas de dÃ©faillance.
* **Batch interval tuning** : Ã‰quilibre latence vs throughput.
* **Connection pooling** : Optimisation des connexions PostgreSQL. 
* **Volumes Docker** : Persistance des donnÃ©es et logs.

---

## ğŸ“ **Support**

Pour toute question, ouvrez une [issue](https://github.com/WassimTorjmen/Spark-Streaming-Project/issues). 

---

## ğŸ‘¤ **Auteur**

**Wassim Torjmen**

---

**DerniÃ¨re mise Ã  jour** : DÃ©cembre 2025
