package com.esgi // D√©clare le package dans lequel se trouve ce fichier

import org.apache.kafka.clients.producer.{KafkaProducer, ProducerRecord} // Importe les classes n√©cessaires pour produire des messages Kafka
import java.util.Properties // Pour configurer Kafka
import java.net.{URL, HttpURLConnection} // Pour faire des requ√™tes HTTP
import scala.io.Source // Pour lire les flux d'entr√©e (ex : r√©ponses HTTP)
import ujson._ // Pour parser et manipuler du JSON

object ProducerKafka { // Objet principal contenant le programme

  // URL de base de l'API HuggingFace pour r√©cup√©rer les produits OpenFoodFacts
  val baseUrl = "https://datasets-server.huggingface.co/rows?dataset=openfoodfacts%2Fproduct-database&config=default&split=food"

  def main(args: Array[String]): Unit = { // Point d'entr√©e du programme

    /* --------- Param√®tres --------- */
    val useAPI      = true // Si true, on lit les donn√©es depuis l‚ÄôAPI ; sinon depuis un fichier local
    val jsonPath    = "data/food.parquet" // Chemin du fichier local (si useAPI = false)
    val batchLength = 100 // Nombre de produits √† r√©cup√©rer/envoyer par batch
    val maxOffset   = 3808300 // Limite maximale d‚Äôoffset pour la pagination API
    val topic       = "openfood" // Nom du topic Kafka
    val bootstrap = sys.env.getOrElse("KAFKA_BOOTSTRAP_SERVERS", "kafka:9092") // Adresse du serveur Kafka

    /* --------- Configuration Kafka --------- */
    val props = new Properties() // Cr√©ation d‚Äôun objet de configuration
    props.put("bootstrap.servers", bootstrap) // Serveur Kafka

    // S√©rialisation de la cl√© et de la valeur en String
    props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer")
    props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer")

    props.put("max.request.size", "2000000") // Limite de taille d‚Äôune requ√™te Kafka (en octets)

    val producer = new KafkaProducer[String, String](props) // Cr√©ation du producteur Kafka
    println("Producer Kafka ‚Äì d√©marrage") // Message d'information

    // Si on utilise l‚ÄôAPI
    if (useAPI) {
      var offset = 0 // Offset de d√©part
      while (offset <= maxOffset) { // Boucle jusqu‚Äô√† atteindre la limite d‚Äôoffset
        val url   = s"$baseUrl&offset=$offset&length=$batchLength" // Construit l‚ÄôURL avec les param√®tres
        val batch = fetchBatchFromAPI(url) // R√©cup√®re un batch de produits (JSON brut)

        if (batch.nonEmpty) { // Si le batch n‚Äôest pas vide
          producer.send(new ProducerRecord(topic, null, batch)) // Envoie le batch dans Kafka
          println(s"Batch offset=$offset envoy√© (${batch.length} chars)") // Affiche confirmation + taille du batch

          // Aper√ßu des donn√©es envoy√©es (limit√© √† 200 caract√®res)
          val preview = if (batch.length > 200) batch.take(200) + "..." else batch
          println(s"üü¢ Batch offset=$offset envoy√©  (${batch.length} chars)")
          println(s"   ‚Ü≥ Aper√ßu : $preview\n")

          Thread.sleep(2000) // Pause de 2 secondes pour √©viter de surcharger l‚ÄôAPI
        } else {
          println(s"API vide √† offset $offset, arr√™t.") // Si aucune donn√©e re√ßue, on arr√™te
        }

        offset += batchLength // Passe au batch suivant
        Thread.sleep(2000) // Petite pause entre chaque requ√™te
      }

    } else {
      // Si on lit depuis un fichier local
      fetchBatchesFromFile(jsonPath).foreach { batch =>
        producer.send(new ProducerRecord(topic, null, batch)) // Envoie chaque batch depuis le fichier
        println(s"Batch fichier envoy√© (${batch.length} chars)") // Affiche confirmation
        Thread.sleep(1000) // Pause entre les envois
      }
    }

    producer.flush() // Force l‚Äôenvoi de tous les messages en attente
    producer.close() // Ferme proprement le producteur Kafka
    println(" Fin d‚Äôenvoi ‚Äì producer Kafka ferm√©.") // Message de fin
  }

  // Fonction qui r√©cup√®re un batch JSON depuis l‚ÄôAPI
  def fetchBatchFromAPI(url: String): String = {
    try {
      val conn = new URL(url).openConnection().asInstanceOf[HttpURLConnection] // Ouvre la connexion HTTP
      conn.setConnectTimeout(2000) // Timeout de connexion
      conn.setReadTimeout(2000) // Timeout de lecture

      val is   = conn.getInputStream // R√©cup√®re le flux de r√©ponse
      val json = Source.fromInputStream(is).mkString // Lit la r√©ponse JSON en cha√Æne de caract√®res
      is.close() // Ferme le flux
      json // Retourne le JSON
    } catch {
      case e: Exception =>
        println(s" API error : ${e.getMessage}") // Affiche l'erreur en cas d‚Äô√©chec
        "" // Retourne une cha√Æne vide
    }
  }

  // Fonction qui lit un fichier local JSON et le d√©coupe en batches de 100 produits
  def fetchBatchesFromFile(path: String): Vector[String] = {
    try {
      val raw   = Source.fromFile(path).mkString // Lit tout le fichier en cha√Æne
      val root  = ujson.read(raw) // Parse le contenu JSON
      val rows  = root("rows").arr.map(_("row")) // R√©cup√®re les lignes (produits)

      // Groupe les lignes par 100, puis les convertit en JSON
      rows.grouped(100).map(g => ujson.Arr(g: _*).render()).toVector
    } catch {
      case e: Exception =>
        println(s" File error : ${e.getMessage}") // Affiche une erreur en cas d‚Äô√©chec
        Vector.empty // Retourne un vecteur vide
    }
  }
}
